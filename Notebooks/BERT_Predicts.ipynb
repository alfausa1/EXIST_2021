{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXIST 2021 - BERT predicts <a class=\"anchor\" id=\"bert-preds\"></a>\n",
    "\n",
    "    ÁLVARO FAUBEL SANCHIS\n",
    "    CLARA MARTÍ TORREGROSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Table of contents :\n",
    "- [Requiered functions](#functions)\n",
    " * [Required libraries and configuration](#libraries)\n",
    " * [Cleaning](#cleaning)\n",
    " * [BERT](#bert)\n",
    "     \n",
    "- [EXIST Task](#exist)\n",
    " * [Data load](#data-load)\n",
    " * [Predictions](#preds)\n",
    "     * [Spanish](#sp)\n",
    "         - [Task 1](#sp-t1)\n",
    "         - [Task 2](#sp-t2)\n",
    "     * [English](#en)\n",
    "         - [Task 1](#en-t1)\n",
    "         - [Task 2](#en-t2)\n",
    " * [Submission results](#submission)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required functions <a class=\"anchor\" id=\"functions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required libraries and configuration <a class=\"anchor\" id=\"libraries\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data & visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytoch \n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "# BERT Hugging Face\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AutoTokenizer, AutoModel\n",
    "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Sklearn: tecnics & methods \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# Configuración: seed & display\n",
    "RANDOM_SEED = 45\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning (optional) <a class=\"anchor\" id=\"cleaning\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "import re\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                            u\"\\U0001F600-\\U0001F64F\"  \n",
    "                            u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                            u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                            u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                            \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def clean_tweet(tweet, special_tokens = True, emoji_pattern = emoji_pattern):\n",
    "    if special_tokens:\n",
    "        text_clean = p.tokenize(tweet)\n",
    "    else:\n",
    "        text_clean = p.clean(tweet)\n",
    "    text_clean_emoji = emoji_pattern.sub(r'', text_clean)\n",
    "    return text_clean_emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT <a class=\"anchor\" id=\"bert\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Class for structure the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetsDataset(Dataset):\n",
    "    def __init__(self, tweets, tokenizer, max_len):\n",
    "        self.tweets = tweets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        tweet = str(self.tweets[item])\n",
    "        encoding = self.tokenizer.encode_plus(tweet,\n",
    "                                              add_special_tokens=True,\n",
    "                                              max_length=self.max_len,\n",
    "                                              return_token_type_ids=False,\n",
    "                                              pad_to_max_length=True,\n",
    "                                              return_attention_mask=True,\n",
    "                                              return_tensors='pt')\n",
    "    \n",
    "        return {'tweet_text': tweet,\n",
    "                'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creation of data loaders objects for the segmentation in packets (batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, column, tokenizer, max_len, batch_size):\n",
    "    ds = TweetsDataset(tweets=df[column].to_numpy(),\n",
    "                       tokenizer=tokenizer,\n",
    "                       max_len=max_len)\n",
    "    return DataLoader(ds, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Custom classifier from pre-trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, model_name):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name) \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu =  nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        self.fc2 = nn.Linear(512,n_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _,cls_hs = self.bert(input_ids, attention_mask=attention_mask, return_dict=False)   \n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "    model = model.eval()\n",
    "    \n",
    "    tweets_texts = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            \n",
    "            texts = d[\"tweet_text\"]\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            #probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            #preds = (probabilities[:,1] > 0.7).float()\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            tweets_texts.extend(texts)\n",
    "            predictions.extend(preds)\n",
    "            prediction_probs.extend(outputs)\n",
    "    \n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "    return predictions, prediction_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXIST Task <a class=\"anchor\" id=\"exist\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load <a class=\"anchor\" id=\"data-load\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_case</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6978</td>\n",
       "      <td>gab</td>\n",
       "      <td>en</td>\n",
       "      <td>Pennsylvania State Rep horrifies with opening ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6979</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>@iilovegrapes He sounds like as ass, and very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6980</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>@averyangryskel1 @4ARealistParty LOL! \"This be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6981</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>@WanderOrange @stalliontwink Rights?I mean yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6982</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>the jack manifold appreciation i’m seeing is o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_case    id   source language  \\\n",
       "0  EXIST2021  6978      gab       en   \n",
       "1  EXIST2021  6979  twitter       en   \n",
       "2  EXIST2021  6980  twitter       en   \n",
       "3  EXIST2021  6981  twitter       en   \n",
       "4  EXIST2021  6982  twitter       en   \n",
       "\n",
       "                                                text  \n",
       "0  Pennsylvania State Rep horrifies with opening ...  \n",
       "1  @iilovegrapes He sounds like as ass, and very ...  \n",
       "2  @averyangryskel1 @4ARealistParty LOL! \"This be...  \n",
       "3  @WanderOrange @stalliontwink Rights?I mean yea...  \n",
       "4  the jack manifold appreciation i’m seeing is o...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../EXIST2021_dataset/test/EXIST2021_test.tsv', sep='\\t')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the dataset into Spanish and English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es = df[df['language'] == 'es']\n",
    "df_en = df[df['language'] == 'en']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicctions <a class=\"anchor\" id=\"preds\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish <a class=\"anchor\" id=\"sp\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task1 <a class=\"anchor\" id=\"sp-t1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-cf9e4adac03e>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_es['text_clean'] = [clean_tweet(tw, special_tokens=True) for tw in df_es.text]\n"
     ]
    }
   ],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.SMILEY, p.OPT.RESERVED) #, p.OPT.HASHTAG p.OPT.NUMBER)\n",
    "\n",
    "df_es['text_clean'] = [clean_tweet(tw, special_tokens=True) for tw in df_es.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the trained and tuned model and tokenizer, and set its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN_ES1 = 155\n",
    "BATCH_SIZE_ES1 = 16\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME_ES1 = 'dccuchile/bert-base-spanish-wwm-cased'\n",
    "tokenizer_es1 = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME_ES1)\n",
    "\n",
    "model_es1 = BERTClassifier(2, PRE_TRAINED_MODEL_NAME_ES1)\n",
    "model_es1.load_state_dict(torch.load('../Models/task1_spanish.bin'))\n",
    "model_es1 = model_es1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the input data-loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_es1 = create_data_loader(df_es, 'text_clean', tokenizer_es1, MAX_LEN_ES1, BATCH_SIZE_ES1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\python\\python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2073: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred_es1, y_pred_probs_es1 = get_predictions(model_es1, data_loader_es1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-8c8ba7c74171>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_es['task1_encoding'] = y_pred_es1.numpy()\n"
     ]
    }
   ],
   "source": [
    "df_es['task1_encoding'] = y_pred_es1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task2 <a class=\"anchor\" id=\"sp-t2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Separate the examples classified as non-sexist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es2 = df_es.drop(df_es.loc[df_es['task1_encoding']==0].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.SMILEY, p.OPT.RESERVED) #, p.OPT.HASHTAG p.OPT.NUMBER)\n",
    "\n",
    "df_es2['text_clean'] = [clean_tweet(tw, special_tokens=True) for tw in df_es2.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the trained and tuned model and tokenizer, and set its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN_ES2 = 120\n",
    "BATCH_SIZE_ES2 = 16\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME_ES2 = 'dccuchile/bert-base-spanish-wwm-cased'\n",
    "tokenizer_es2 = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME_ES2)\n",
    "\n",
    "model_es2 = BERTClassifier(5, PRE_TRAINED_MODEL_NAME_ES2)\n",
    "model_es2.load_state_dict(torch.load('../Models/task2_spanish.bin'))\n",
    "model_es2 = model_es2.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the input data-loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_es2 = create_data_loader(df_es2, 'text_clean', tokenizer_es2, MAX_LEN_ES2, BATCH_SIZE_ES2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\python\\python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2073: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred_es2, y_pred_probs_es2 = get_predictions(model_es2, data_loader_es2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_es2['task2_encoding'] = y_pred_es2.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English <a class=\"anchor\" id=\"en\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task1 <a class=\"anchor\" id=\"en-t1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-4c48e420df08>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_en['text_clean'] = [clean_tweet(tw, special_tokens=True) for tw in df_en.text]\n"
     ]
    }
   ],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.SMILEY, p.OPT.RESERVED, p.OPT.HASHTAG, p.OPT.NUMBER)\n",
    "\n",
    "df_en['text_clean'] = [clean_tweet(tw, special_tokens=True) for tw in df_en.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the trained and tuned model and tokenizer, and set its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN_EN1 = 170\n",
    "BATCH_SIZE_EN1 = 16\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME_EN1 = 'cardiffnlp/twitter-roberta-base'\n",
    "tokenizer_en1 = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME_EN1)\n",
    "\n",
    "model_en1 = BERTClassifier(2, PRE_TRAINED_MODEL_NAME_EN1)\n",
    "model_en1.load_state_dict(torch.load('../Models/task1_english.bin'))\n",
    "model_en1 = model_en1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the input data-loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_en1 = create_data_loader(df_en, 'text_clean', tokenizer_en1, MAX_LEN_EN1, BATCH_SIZE_EN1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "y_pred_en1, y_pred_probs_en1 = get_predictions(model_en1, data_loader_en1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-6bcf4cb57eab>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_en['task1_encoding'] = y_pred_en1.numpy()\n"
     ]
    }
   ],
   "source": [
    "df_en['task1_encoding'] = y_pred_en1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task2 <a class=\"anchor\" id=\"en-t2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Separate the examples classified as non-sexist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en2 = df_en.drop(df_en.loc[df_en['task1_encoding']==0].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.SMILEY, p.OPT.RESERVED, p.OPT.HASHTAG, p.OPT.NUMBER)\n",
    "\n",
    "df_en2['text_clean'] = [clean_tweet(tw, special_tokens=True) for tw in df_en2.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the trained and tuned model and tokenizer, and set its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN_EN2 = 170\n",
    "BATCH_SIZE_EN2 = 16\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME_EN2 = 'cardiffnlp/twitter-roberta-base'\n",
    "tokenizer_en2 = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME_EN2)\n",
    "\n",
    "model_en2 = BERTClassifier(5, PRE_TRAINED_MODEL_NAME_EN2)\n",
    "model_en2.load_state_dict(torch.load('../Models/task2_english.bin'))\n",
    "model_en2 = model_en2.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the input data-loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_en2 = create_data_loader(df_en2, 'text_clean', tokenizer_en2, MAX_LEN_EN2, BATCH_SIZE_EN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\python\\python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2073: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred_en2, y_pred_probs_en2 = get_predictions(model_en2, data_loader_en2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_en2['task2_encoding'] = y_pred_en2.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission results <a class=\"anchor\" id=\"submission\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Concatenate the dataframes obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_case</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>task1_encoding</th>\n",
       "      <th>task2_encoding</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6978</td>\n",
       "      <td>gab</td>\n",
       "      <td>en</td>\n",
       "      <td>Pennsylvania State Rep horrifies with opening ...</td>\n",
       "      <td>Pennsylvania State Rep horrifies with opening ...</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6979</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>@iilovegrapes He sounds like as ass, and very ...</td>\n",
       "      <td>$MENTION$ He sounds like as ass, and very cond...</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6980</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>@averyangryskel1 @4ARealistParty LOL! \"This be...</td>\n",
       "      <td>$MENTION$ $MENTION$ LOL! \"This behavior of not...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6981</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>@WanderOrange @stalliontwink Rights?I mean yea...</td>\n",
       "      <td>$MENTION$ $MENTION$ Rights?I mean yeah most wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6982</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>the jack manifold appreciation i’m seeing is o...</td>\n",
       "      <td>the jack manifold appreciation i’m seeing is o...</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_case    id   source language  \\\n",
       "0  EXIST2021  6978      gab       en   \n",
       "1  EXIST2021  6979  twitter       en   \n",
       "2  EXIST2021  6980  twitter       en   \n",
       "3  EXIST2021  6981  twitter       en   \n",
       "4  EXIST2021  6982  twitter       en   \n",
       "\n",
       "                                                text  \\\n",
       "0  Pennsylvania State Rep horrifies with opening ...   \n",
       "1  @iilovegrapes He sounds like as ass, and very ...   \n",
       "2  @averyangryskel1 @4ARealistParty LOL! \"This be...   \n",
       "3  @WanderOrange @stalliontwink Rights?I mean yea...   \n",
       "4  the jack manifold appreciation i’m seeing is o...   \n",
       "\n",
       "                                          text_clean  task1_encoding  \\\n",
       "0  Pennsylvania State Rep horrifies with opening ...               0   \n",
       "1  $MENTION$ He sounds like as ass, and very cond...               0   \n",
       "2  $MENTION$ $MENTION$ LOL! \"This behavior of not...               1   \n",
       "3  $MENTION$ $MENTION$ Rights?I mean yeah most wo...               1   \n",
       "4  the jack manifold appreciation i’m seeing is o...               0   \n",
       "\n",
       "  task2_encoding       task1                   task2  \n",
       "0     non-sexist  non-sexist              non-sexist  \n",
       "1     non-sexist  non-sexist              non-sexist  \n",
       "2            0.0      sexist  ideological-inequality  \n",
       "3            0.0      sexist  ideological-inequality  \n",
       "4     non-sexist  non-sexist              non-sexist  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task1 = pd.concat([df_en, df_es])\n",
    "df_task2 = pd.concat([df_en2, df_es2])\n",
    "df_both = pd.merge(df_task1, df_task2[['id', 'task2_encoding']], left_on='id',  right_on='id', how='outer')\n",
    "\n",
    "df_both['task2_encoding'] = df_both['task2_encoding'].fillna('non-sexist')\n",
    "df_both['task1'] = df_both['task1_encoding'].replace({0: 'non-sexist',\n",
    "                                               1: 'sexist'})\n",
    "\n",
    "df_both['task2'] = df_both['task2_encoding'].replace({0: 'ideological-inequality',\n",
    "                                                        1: 'stereotyping-dominance',\n",
    "                                                        2: 'misogyny-non-sexual-violence',\n",
    "                                                        3: 'sexual-violence', \n",
    "                                                        4: 'objectification'})\n",
    "df_both.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Format the results for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_case</th>\n",
       "      <th>id</th>\n",
       "      <th>task1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>006978</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>006979</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>006980</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>006981</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>006982</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_case      id       task1\n",
       "0  EXIST2021  006978  non-sexist\n",
       "1  EXIST2021  006979  non-sexist\n",
       "2  EXIST2021  006980      sexist\n",
       "3  EXIST2021  006981      sexist\n",
       "4  EXIST2021  006982  non-sexist"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final1 = pd.DataFrame({'test_case': df_both['test_case'],\n",
    "                        'id': df_both['id'].apply(lambda x: str(x).zfill(6)),\n",
    "                        'task1': df_both['task1']})\n",
    "df_final1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final1.to_csv('../Submission/exist2021_Alclatos/task1_Alclatos_1.tsv', sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_case</th>\n",
       "      <th>id</th>\n",
       "      <th>task2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>006978</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>006979</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>006980</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>006981</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>006982</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_case      id                   task2\n",
       "0  EXIST2021  006978              non-sexist\n",
       "1  EXIST2021  006979              non-sexist\n",
       "2  EXIST2021  006980  ideological-inequality\n",
       "3  EXIST2021  006981  ideological-inequality\n",
       "4  EXIST2021  006982              non-sexist"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final2 = pd.DataFrame({'test_case': df_both['test_case'],\n",
    "                        'id': df_both['id'].apply(lambda x: str(x).zfill(6)),\n",
    "                        'task2': df_both['task2']})\n",
    "df_final2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2.to_csv('../Submission/exist2021_Alclatos/task2_Alclatos_1.tsv', sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
